\section{Cryptography}
\label{sec:cryptography}

\subsection{Secure hash functions}

Hash functions are deterministic functions that take input of arbitrary length, a preimage, and produce an output of fixed length, a hash \cite[p.~153]{lindell2014introduction}. When the preimage is much larger than the output length, the hash function is effectively a lossy compress function. A hash function can be used for different purposes, and can be designed to have properties fit for its purpose. A secure hash function is one that has properties that makes it useful for a range of cryptographic purposes. 

\subsubsection{Properties of secure hash functions}

\noindent
{\bf Collision resistance.}
A hash function is collision resistant if it is infeasible to find two preimages $m$ and $m'$ where $m \neq m'$ so that $Hash(m) = Hash(m')$. Such $m$ and $m'$ must exist, as the domain of arbitrary length inputs is larger than the range of fixed length outputs. But the length of outputs in secure hash functions can be so large that it's computationally infeasible to find such preimages. 
A hash function that is collision resistant will implicitly also be \emph{preimage resistant} and \emph{second-preimage resistant}. Second-preimage resistance means that given a preimage $m$ it is infeasible to find a $m' \neq m$ so that $Hash(m) = Hash(m')$. Preimage resistance essentially means that a hash function is one-way.

\noindent
{\bf One-way.}
A secure hash function is a one-way function in that it should not be possible to find the preimage $m$ given a hash $h = Hash(m)$ by any other means that guessing all possible $m$, i.e. a secure hash function should be infeasible to invert. In cryptographic applications, this property makes it possible to publicly share hashes of secret preimages without risking compromising the secrets. We will see that this can be useful when a secret $s$ at a later point will be revealed, as it makes it possible to verify that a previously shared hash $h$ is indeed the hash of a secret by verifying that $Hash(s) = h$.

\noindent
{\bf Avalanche effect.}
The avalanche effect is a term used to describe that a small change in a function's input will have a large effect on its output. A strict criterion for the avalanche effect is that any change in the input of a hash function causes each bit in the output to flip with a probability of 0.5. If similar hashes are more likely to come from similar preimages, this makes it possible to make good guesses when attempting to reverse a hash function by employing statistical analysis.

\subsubsection{Some applications of secure hash functions}

\noindent
{\bf Hashing to verify message integrity and authenticity.}
Hash functions can be used to verify the integrity of a message. We assume one party, Alice, has received the hash $H$ of a long message $m$ from a trusted party. Another party Alice does not trust, Bob, claims to have $m$ and offers to transmit it to Alice. Since Alice knows the hash of the message, she can retrieve the message from Bob and independently verify the message's integrity and authenticity by verifying that $Hash(m) = h$. This makes it possible to e.g. retrieve large files from untrusted parties while only retrieving small hashes from trusted parties. This concept is used and specified to be used in HMACs \cite[p.~158--164]{lindell2014introduction}.

\noindent
{\bf Hashes as digital fingerprints.}
The hash of any digital representation of information, such as a file, can be considered as almost unique if the hash function is collision resistant. This enables the hash be used as an identifier or fingerprint. This is useful in content addressing and resource lookup in distributed file systems. This concept is also useful for deduplication, as it provides a method for discovering identical files within a storage system~\cite[p.~182-183]{lindell2014introduction}. 

\noindent
{\bf Data structures linked by hashes.}
Blocks of data can be hashed and addressed by its hash, as a data block's hash serve as an identifier. If a data block contains the hash of another block, we can create acyclic data structures with useful properties in integrity and authenticity. This can be used to verify membership of some item in a collection without knowing the entire collection.

A common data structure that uses data linked by hashes is Merkle trees \cite{merkle_digital_1988}. A collection of data blocks are ordered in $\{block_0, block_1, ..., block_n\}$. The ordered items form the leaves of a full binary tree. The collection is padded with empty items if its cardinality is not a power of two. Each internal node is identified by the hash of the concatenation of its children, and each leaf node by the hash of its content. The root of any subtree will be a dependent on the data of the items in its leaf nodes, and a change of the data in any item of the collection will cause a change in the identifiers of the root of each subtree that contains the item. 
This makes it possible to verify that an item exist in a collection if the verifier only knows the identifier of the root node and the hash of the item they wish to verify the membership of. A proves needs to provide the item as well as the identifiers of all nodes in the path from the leaf node to the root node. 

\noindent
{\bf Hash functions as random oracles.}
A secure hash function is collision resistant. The implication of this is that no observer can know the message by seeing only the hash, or know the hash of a message without calculating it. The avalanche effect makes it so that the mapping of inputs to outputs form a uniform distribution of the range with all inputs being independent. This is a stronger assumption than simply preimage and second preimage resistance, and is not formally proven by any hash algorithm \cite[p.~179-181]{lindell2014introduction}. Still, many applications assume that secure hash functions' outputs are uniformly distributed. Since this property is not formally proven, a \emph{random oracle model} assumption is often made for hash functions. Under the random oracle model, a given hash function is assumed to have outputs uniformly distributed and inhibit the avalanche effect.

\noindent
{\bf Hashes in commitment schemes.}
A party can publish the hash of a message at some time t to prove that it possessed the message at time t. The committing party does not need to reveal anything about the message if the assume the hash function is preimage resistant \cite[p.~187--189]{lindell2014introduction}. This concept can be used in commitment schemes \cite{brassard1988minimum} to create an unpredictable, but reproducible number that can be used as a seed to a pseudo-random function, which allows untrusting parties to agree on random numbers as in \cite{blum1983coin}.

\noindent
{\bf Hashing in proof-of-work (PoW).}
Under the random oracle model, all values within the range of a hash function are equally to be the output for any given input. We can define a subspace within the range of any size and know the probability of finding an input that maps to that subspace. E.g. if the range is all bitstrings with length $l=256$, we can define a subspace of the range to be all bitstrings of length $l$ where the first $z$ leading bits are zero. The probability of an input mapping to this subspace will be $p_z=\frac{1}{2^z}$. If we assume that calculating a hash has a cost, we see that finding an input that maps to a limited range has an expected cost. This makes it arbitrarily hard rather than infeasible to find a certain preimage. While finding such a preimage may require millions of trials, verifying that an input maps to the subspace requires only one calculation of the hash function.  

This fact has been used to enforce a price to be paid in number of expected computations to be executed in some online protocols \cite{dwork_pricing_1993} \cite{back_hashcash-denial_2002}. In order to prevent reusing of known hashes, a unique challenge $c$ can be issued to the prover who pays the price. The prover must produce a hash so that $Hash(c || n) \in SS$ where $SS$ is the subspace, $||$ is the concatenation operator, and $n$ is a nonce which can be any value. 


\subsection{Digital encryption}

Digital encryption is realized by a set of algorithms $Encrypt(m, k) \Rightarrow c$ and $decrypt(c, k) \Rightarrow m$. $m$ is a message, $c$ is a cipher and $k$ is a key. A message is securely encrypted if it is computationally unfeasible to decrypt the message without knowing $k$. In symmetric cryptography the same key is used for encryption and decryption, while in asymmetric cryptography different keys are used for encryption and decryption. The former is typically used for secure communication over an insecure channel while the latter is used for both secure communication and to enable digital signatures.

\subsubsection{Public and private key pairs}

In \cite{diffie1976new}, Diffie and Hellman describe an interactive protocol that makes it possible to perform an interactive secure key exchange, often called a handshake, between parties over an insecure channel where they can securely generate a secret key. In addition to what became known as the Diffie-Hellman key exchange, the seminal 1976 paper also introduced the concept asymmetric cryptography, and is often considered to mark the beginning of a cryptographic revolution that made it possible to use very strong cryptography using commodity computing devices and public infrastructure. 

In a public-key encryption scheme, a pair of keys $(pk, sk)$ are generated so that one can be used to decrypt messages that are encrypted by the other. The keys in the pair serve different roles; a public key $pk$ is widely disseminated and is used to encrypt messages intended for the receiver who knows the corresponding secret key $sk$ â€“ the other key in the pair, which can decrypt the message \cite[p.~370]{lindell2014introduction}. This makes it possible for parties to communicate confidentially by only knowing each other's public key in advance, i.e. no secure key exchange in advance is necessary. 

A secure network using public-key schemes has some scaling advantages as well. In a network of $n$ nodes where each node wishes to communicate securely and privately with any other node, the network would need to store $n$ public keys and $n$ private keys in aggregate. With a private-key scheme, there would have to be a key for each pair of nodes, i.e. one key for each edge in a fully connected graph of $n$ nodes, which is $(n-1)^2$ keys in aggregate. We see that the former scales linearly and the latter scales polynomially with regards to keys stored. 

\subsection{Digital signatures}

Digital signatures makes it possible to prove that a message has been signed by a certain party. A digital signature scheme consist of a set of probabilistic polynomial time algorithms: $Generate(n)$ which outputs an asymmetric key pair $(pk, sk)$ where $n$ is a security parameter; $Sign(sk, m)$ which outputs a signature $\sigma$; $Verify(pk, m, \sigma)$ which outputs $true$ iff $Sign(sk, m) = \sigma$ or $false$ otherwise \footnote{With negligible probability of this not happening.}. Such a scheme can be implemented by encrypting a message with a private key that is known to belong to a certain party. If we assume a network where participants are aware of each other's public keys, one can authenticate oneself by encrypting a predefined message. Consider the public-private key pair $(pk_{Alice}, sk_{Alice})$ and the predefined challenge $c$. A signature $\sigma$ is created with $\sigma := Encrypt(c, sk_{Alice})$. The signature is verified if $c=Decrypt(\sigma, pk_{Alice})$. The verifier will be able to authenticate Alice and Alice will not be able to repudiate that she did sign the challenge. Typically a challenge is signed together with a nonce such as a timestamp to prevent replay attacks, where the verifier poses as Alice by reusing the signature.

While signing predefined challenges is useful for authentication, the same principle can also be used to sign arbitrary data such as messages generated by the signer. Instead of encrypting the entire message and using that as a signature, typically only the hash of the message is signed and sent along with the message. The sender, Alice, hashes the message $m$ so that we have the hash $h=Hash(m)$. The signature is $\sigma := Encrypt(h, sk_{Alice})$. The receiver will hash the message and verify its integrity and authenticity by verifying that $Hash(m)=Decrypt(\sigma, pk_{Alice})$.
